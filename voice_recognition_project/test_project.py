"""
Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ù…Ø´Ø±ÙˆØ¹ ØªÙ…ÙŠÙŠØ² Ø§Ù„Ø£ØµÙˆØ§Øª
Tests for Voice Recognition Project
"""

import unittest
import numpy as np
import tempfile
import os
from pathlib import Path
import warnings
warnings.filterwarnings("ignore")

class TestVoiceRecognizer(unittest.TestCase):
    """Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ù†Ù…ÙˆØ°Ø¬ ØªÙ…ÙŠÙŠØ² Ø§Ù„Ø£ØµÙˆØ§Øª"""
    
    def setUp(self):
        """Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª"""
        try:
            from voice_recognizer import VoiceRecognizer
            self.recognizer = VoiceRecognizer()
        except Exception as e:
            self.skipTest(f"Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØ­Ù…ÙŠÙ„ VoiceRecognizer: {e}")
    
    def test_recognizer_initialization(self):
        """Ø§Ø®ØªØ¨Ø§Ø± ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"""
        self.assertIsNotNone(self.recognizer)
        self.assertIsNotNone(self.recognizer.recognizer)
    
    def test_extract_features(self):
        """Ø§Ø®ØªØ¨Ø§Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø®ØµØ§Ø¦Øµ"""
        # Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØª ØªØ¬Ø±ÙŠØ¨ÙŠ
        sample_rate = 22050
        duration = 1.0
        frequency = 440.0  # Ù†ØºÙ…Ø© A4
        
        t = np.linspace(0, duration, int(sample_rate * duration))
        audio = np.sin(2 * np.pi * frequency * t)
        
        # Ø­ÙØ¸ Ø§Ù„ØµÙˆØª ÙÙŠ Ù…Ù„Ù Ù…Ø¤Ù‚Øª
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:
            import soundfile as sf
            sf.write(tmp_file.name, audio, sample_rate)
            
            try:
                # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø®ØµØ§Ø¦Øµ
                features = self.recognizer.extract_features(tmp_file.name)
                
                self.assertIsInstance(features, dict)
                self.assertIn('duration', features)
                self.assertIn('sample_rate', features)
                self.assertIn('mfcc', features)
                
                # ÙØ­Øµ Ø§Ù„Ù‚ÙŠÙ…
                self.assertGreater(features['duration'], 0)
                self.assertEqual(features['sample_rate'], sample_rate)
                self.assertEqual(len(features['mfcc']), 13)
                
            finally:
                os.unlink(tmp_file.name)
    
    def test_analyze_emotion(self):
        """Ø§Ø®ØªØ¨Ø§Ø± ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±"""
        # Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØª ØªØ¬Ø±ÙŠØ¨ÙŠ
        sample_rate = 22050
        duration = 2.0
        frequency = 440.0
        
        t = np.linspace(0, duration, int(sample_rate * duration))
        audio = np.sin(2 * np.pi * frequency * t)
        
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:
            import soundfile as sf
            sf.write(tmp_file.name, audio, sample_rate)
            
            try:
                # Ø§Ø®ØªØ¨Ø§Ø± ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
                emotion_results = self.recognizer.analyze_emotion(tmp_file.name)
                
                self.assertIsInstance(emotion_results, dict)
                
                # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…ØªÙˆÙØ±Ø§Ù‹
                if 'emotions' in emotion_results:
                    self.assertIsInstance(emotion_results['emotions'], list)
                    if emotion_results['emotions']:
                        emotion = emotion_results['emotions'][0]
                        self.assertIn('label', emotion)
                        self.assertIn('score', emotion)
                
            finally:
                os.unlink(tmp_file.name)
    
    def test_detect_speaker_characteristics(self):
        """Ø§Ø®ØªØ¨Ø§Ø± ÙƒØ´Ù Ø®ØµØ§Ø¦Øµ Ø§Ù„Ù…ØªØ­Ø¯Ø«"""
        # Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØª ØªØ¬Ø±ÙŠØ¨ÙŠ
        sample_rate = 22050
        duration = 1.0
        frequency = 440.0
        
        t = np.linspace(0, duration, int(sample_rate * duration))
        audio = np.sin(2 * np.pi * frequency * t)
        
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:
            import soundfile as sf
            sf.write(tmp_file.name, audio, sample_rate)
            
            try:
                # Ø§Ø®ØªØ¨Ø§Ø± ÙƒØ´Ù Ø®ØµØ§Ø¦Øµ Ø§Ù„Ù…ØªØ­Ø¯Ø«
                speaker_results = self.recognizer.detect_speaker_characteristics(tmp_file.name)
                
                self.assertIsInstance(speaker_results, dict)
                
                if 'error' not in speaker_results:
                    self.assertIn('pitch_range', speaker_results)
                    self.assertIn('energy_level', speaker_results)
                    self.assertIn('voice_quality', speaker_results)
                    self.assertIn('estimated_gender', speaker_results)
                
            finally:
                os.unlink(tmp_file.name)

class TestAudioProcessor(unittest.TestCase):
    """Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„ØµÙˆØª"""
    
    def setUp(self):
        """Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª"""
        try:
            from audio_utils import AudioProcessor
            self.processor = AudioProcessor()
        except Exception as e:
            self.skipTest(f"Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØ­Ù…ÙŠÙ„ AudioProcessor: {e}")
    
    def test_processor_initialization(self):
        """Ø§Ø®ØªØ¨Ø§Ø± ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬"""
        self.assertIsNotNone(self.processor)
        self.assertEqual(self.processor.sample_rate, 22050)
    
    def test_normalize_audio(self):
        """Ø§Ø®ØªØ¨Ø§Ø± ØªØ·Ø¨ÙŠØ¹ Ø§Ù„ØµÙˆØª"""
        # Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØª ØºÙŠØ± Ø·Ø¨ÙŠØ¹ÙŠ
        audio = np.array([0.1, 0.5, -0.3, 0.8, -0.2])
        
        normalized = self.processor.normalize_audio(audio)
        
        self.assertIsInstance(normalized, np.ndarray)
        self.assertEqual(len(normalized), len(audio))
        self.assertLessEqual(np.max(np.abs(normalized)), 1.0)
    
    def test_apply_bandpass_filter(self):
        """Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø±Ø´Ø­ ØªÙ…Ø±ÙŠØ± Ø§Ù„Ù†Ø·Ø§Ù‚"""
        # Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØª ØªØ¬Ø±ÙŠØ¨ÙŠ
        sample_rate = 22050
        duration = 1.0
        frequency = 440.0
        
        t = np.linspace(0, duration, int(sample_rate * duration))
        audio = np.sin(2 * np.pi * frequency * t)
        
        # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø±Ø´Ø­
        filtered_audio = self.processor.apply_bandpass_filter(audio, sr=sample_rate)
        
        self.assertIsInstance(filtered_audio, np.ndarray)
        self.assertEqual(len(filtered_audio), len(audio))
    
    def test_extract_spectral_features(self):
        """Ø§Ø®ØªØ¨Ø§Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø®ØµØ§Ø¦Øµ Ø§Ù„Ø·ÙŠÙÙŠØ©"""
        # Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØª ØªØ¬Ø±ÙŠØ¨ÙŠ
        sample_rate = 22050
        duration = 1.0
        frequency = 440.0
        
        t = np.linspace(0, duration, int(sample_rate * duration))
        audio = np.sin(2 * np.pi * frequency * t)
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø®ØµØ§Ø¦Øµ
        features = self.processor.extract_spectral_features(audio, sr=sample_rate)
        
        self.assertIsInstance(features, dict)
        self.assertIn('spectral_centroid', features)
        self.assertIn('spectral_rolloff', features)
        self.assertIn('mfcc', features)
        self.assertIn('chroma', features)
        
        # ÙØ­Øµ Ø§Ù„Ù‚ÙŠÙ…
        self.assertGreater(features['spectral_centroid'], 0)
        self.assertGreater(features['spectral_rolloff'], 0)
        self.assertEqual(len(features['mfcc']), 13)
        self.assertEqual(len(features['chroma']), 12)
    
    def test_detect_silence(self):
        """Ø§Ø®ØªØ¨Ø§Ø± ÙƒØ´Ù Ø§Ù„ØµÙ…Øª"""
        # Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØª Ù…Ø¹ ÙØªØ±Ø§Øª ØµÙ…Øª
        sample_rate = 22050
        duration = 2.0
        
        # ØµÙˆØª + ØµÙ…Øª + ØµÙˆØª
        audio = np.concatenate([
            np.sin(2 * np.pi * 440 * np.linspace(0, 0.5, int(sample_rate * 0.5))),
            np.zeros(int(sample_rate * 0.5)),  # ØµÙ…Øª
            np.sin(2 * np.pi * 440 * np.linspace(0, 1.0, int(sample_rate * 1.0)))
        ])
        
        # ÙƒØ´Ù Ø§Ù„ØµÙ…Øª
        silence_segments = self.processor.detect_silence(audio)
        
        self.assertIsInstance(silence_segments, list)
        # ÙŠØ¬Ø¨ Ø£Ù† Ù†Ø¬Ø¯ ÙØªØ±Ø© ØµÙ…Øª ÙˆØ§Ø­Ø¯Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„
    
    def test_enhance_audio(self):
        """Ø§Ø®ØªØ¨Ø§Ø± ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØª"""
        # Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØª ØªØ¬Ø±ÙŠØ¨ÙŠ
        sample_rate = 22050
        duration = 1.0
        frequency = 440.0
        
        t = np.linspace(0, duration, int(sample_rate * duration))
        audio = np.sin(2 * np.pi * frequency * t)
        
        # ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØª
        enhanced = self.processor.enhance_audio(audio, sr=sample_rate)
        
        self.assertIsInstance(enhanced, np.ndarray)
        self.assertLessEqual(len(enhanced), len(audio))  # Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø£Ù‚ØµØ± Ø¨Ø¹Ø¯ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙ…Øª

class TestConfig(unittest.TestCase):
    """Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª"""
    
    def test_config_import(self):
        """Ø§Ø®ØªØ¨Ø§Ø± Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª"""
        try:
            from config import Config, AudioConfig, UIConfig, ModelConfig
            self.assertIsNotNone(Config)
            self.assertIsNotNone(AudioConfig)
            self.assertIsNotNone(UIConfig)
            self.assertIsNotNone(ModelConfig)
        except ImportError as e:
            self.fail(f"ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª: {e}")
    
    def test_config_values(self):
        """Ø§Ø®ØªØ¨Ø§Ø± Ù‚ÙŠÙ… Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª"""
        from config import Config
        
        self.assertIsInstance(Config.PROJECT_NAME, str)
        self.assertIsInstance(Config.VERSION, str)
        self.assertIsInstance(Config.DEFAULT_SAMPLE_RATE, int)
        self.assertIsInstance(Config.SUPPORTED_LANGUAGES, dict)
        self.assertIsInstance(Config.SUPPORTED_AUDIO_FORMATS, list)
        
        # ÙØ­Øµ Ø§Ù„Ù‚ÙŠÙ…
        self.assertGreater(Config.DEFAULT_SAMPLE_RATE, 0)
        self.assertGreater(len(Config.SUPPORTED_LANGUAGES), 0)
        self.assertGreater(len(Config.SUPPORTED_AUDIO_FORMATS), 0)
    
    def test_config_methods(self):
        """Ø§Ø®ØªØ¨Ø§Ø± Ø¯ÙˆØ§Ù„ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª"""
        from config import Config
        
        # Ø§Ø®ØªØ¨Ø§Ø± Ø¯Ø§Ù„Ø© ÙØ­Øµ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚
        self.assertTrue(Config.is_supported_format('test.wav'))
        self.assertTrue(Config.is_supported_format('test.mp3'))
        self.assertFalse(Config.is_supported_format('test.txt'))
        
        # Ø§Ø®ØªØ¨Ø§Ø± Ø¯Ø§Ù„Ø© Ø§Ø³Ù… Ø§Ù„Ù„ØºØ©
        self.assertEqual(Config.get_language_name('ar'), 'Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©')
        self.assertEqual(Config.get_language_name('en'), 'Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©')
        self.assertEqual(Config.get_language_name('unknown'), 'unknown')

class TestIntegration(unittest.TestCase):
    """Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„ØªÙƒØ§Ù…Ù„"""
    
    def test_full_pipeline(self):
        """Ø§Ø®ØªØ¨Ø§Ø± Ø®Ø· Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙƒØ§Ù…Ù„"""
        try:
            from voice_recognizer import VoiceRecognizer
            from audio_utils import AudioProcessor
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø«ÙŠÙ„Ø§Øª
            recognizer = VoiceRecognizer()
            processor = AudioProcessor()
            
            # Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØª ØªØ¬Ø±ÙŠØ¨ÙŠ
            sample_rate = 22050
            duration = 2.0
            frequency = 440.0
            
            t = np.linspace(0, duration, int(sample_rate * duration))
            audio = np.sin(2 * np.pi * frequency * t)
            
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:
                import soundfile as sf
                sf.write(tmp_file.name, audio, sample_rate)
                
                try:
                    # Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒØ§Ù…Ù„Ø©
                    results = recognizer.process_audio_file(tmp_file.name, language="en")
                    
                    self.assertIsInstance(results, dict)
                    self.assertIn('transcription', results)
                    self.assertIn('emotion_analysis', results)
                    self.assertIn('audio_features', results)
                    self.assertIn('speaker_characteristics', results)
                    
                finally:
                    os.unlink(tmp_file.name)
        
        except Exception as e:
            self.skipTest(f"ÙØ´Ù„ ÙÙŠ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªÙƒØ§Ù…Ù„: {e}")

def run_tests():
    """ØªØ´ØºÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª"""
    print("ğŸ§ª Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ù…Ø´Ø±ÙˆØ¹ ØªÙ…ÙŠÙŠØ² Ø§Ù„Ø£ØµÙˆØ§Øª...")
    print("=" * 60)
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
    test_suite = unittest.TestSuite()
    
    # Ø¥Ø¶Ø§ÙØ© Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
    test_suite.addTest(unittest.makeSuite(TestVoiceRecognizer))
    test_suite.addTest(unittest.makeSuite(TestAudioProcessor))
    test_suite.addTest(unittest.makeSuite(TestConfig))
    test_suite.addTest(unittest.makeSuite(TestIntegration))
    
    # ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(test_suite)
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    print("=" * 60)
    if result.wasSuccessful():
        print("ğŸ‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ù†Ø¬Ø­Øª!")
        return True
    else:
        print(f"âŒ ÙØ´Ù„ {len(result.failures)} Ø§Ø®ØªØ¨Ø§Ø±")
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ {len(result.errors)} Ø§Ø®ØªØ¨Ø§Ø±")
        return False

if __name__ == "__main__":
    success = run_tests()
    exit(0 if success else 1)