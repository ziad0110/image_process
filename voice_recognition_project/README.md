# 🎤 نظام تمييز الأصوات الذكي

نظام متقدم لتمييز الأصوات وتحليلها باستخدام تقنيات الذكاء الاصطناعي والتعلم الآلي. يوفر النظام إمكانيات تحويل الصوت إلى نص، تحليل المشاعر، واستخراج خصائص الصوت المتقدمة مع واجهات تفاعلية سهلة الاستخدام.

## 🌟 الميزات الرئيسية

### 🎙️ تحويل الصوت إلى نص
- **Whisper**: نموذج OpenAI المتقدم للتعرف على الكلام
- **Google Speech Recognition**: خدمة Google للتعرف على الكلام
- **Sphinx**: نظام التعرف المحلي
- **دعم لغات متعددة**: العربية، الإنجليزية، الفرنسية، الإسبانية، الألمانية، الإيطالية

### 😊 تحليل المشاعر
- تحليل المشاعر من نبرة الصوت
- تصنيف المشاعر المختلفة (سعيد، حزين، غاضب، محايد، إلخ)
- عرض النتائج برسوم بيانية تفاعلية

### 🎵 استخراج خصائص الصوت
- **MFCC**: معاملات التردد السيبستروم
- **Chroma**: خصائص اللون الصوتي
- **Tonnetz**: خصائص التوافقيات
- **Spectral Features**: الخصائص الطيفية المتقدمة
- **Zero Crossing Rate**: معدل العبور الصفري
- **RMS Energy**: طاقة الصوت

### 👤 تحليل خصائص المتحدث
- تقدير جنس المتحدث
- تحليل نوعية الصوت (ناعم/خشن)
- حساب معدل الكلام
- تحليل استقرار الصوت
- قياس نطاق النبرة

### 🛠️ معالجة الصوت المتقدمة
- إزالة الضوضاء
- تطبيع الصوت
- مرشحات تمرير النطاق
- كشف وإزالة فترات الصمت
- تحسين جودة الصوت
- تحليل جودة الصوت

## 🚀 التثبيت والتشغيل

### المتطلبات
- Python 3.8 أو أحدث
- نظام تشغيل Linux/Windows/macOS
- ميكروفون (للتسجيل المباشر)
- ذاكرة وصول عشوائي 4GB على الأقل

### التثبيت السريع

1. **استنساخ المشروع**
```bash
git clone <repository-url>
cd voice_recognition_project
```

2. **تثبيت المتطلبات**
```bash
python main.py --install
```

أو يدوياً:
```bash
pip install -r requirements.txt
```

3. **اختبار النماذج**
```bash
python main.py --test
```

4. **تشغيل الواجهة**

**واجهة Streamlit (مستحسنة):**
```bash
python main.py --interface streamlit
```

**واجهة Gradio:**
```bash
python main.py --interface gradio
```

### خيارات التشغيل المتقدمة

```bash
# تشغيل على منفذ مخصص
python main.py --interface streamlit --port 8080

# تشغيل على عنوان IP محدد
python main.py --interface streamlit --host 192.168.1.100

# تشغيل في وضع التصحيح
python main.py --interface streamlit --debug
```

## 📱 كيفية الاستخدام

### 1. واجهة Streamlit

1. **افتح المتصفح** وانتقل إلى `http://localhost:8501`
2. **اختر اللغة** من القائمة المنسدلة
3. **تسجيل مباشر**: اضغط "بدء التسجيل" وتحدث لمدة محددة
4. **رفع ملف**: ارفع ملف صوتي من جهازك
5. **اختر خيارات التحليل** (المشاعر، الخصائص، المتحدث)
6. **اضغط "تحليل الصوت"** للحصول على النتائج

### 2. واجهة Gradio

1. **افتح المتصفح** وانتقل إلى `http://localhost:7860`
2. **اختر الإعدادات** من الشريط الجانبي
3. **ارفع ملف صوتي** أو استخدم التسجيل المباشر
4. **اضغط "تحليل الصوت"** لرؤية النتائج

## 📁 هيكل المشروع

```
voice_recognition_project/
├── main.py                 # الملف الرئيسي للتشغيل
├── voice_recognizer.py     # نموذج تمييز الأصوات الأساسي
├── streamlit_app.py        # واجهة Streamlit
├── gradio_app.py          # واجهة Gradio
├── audio_utils.py         # أدوات معالجة الصوت المتقدمة
├── requirements.txt       # المتطلبات
└── README.md             # هذا الملف
```

## 🔧 الاستخدام البرمجي

### استخدام نموذج تمييز الأصوات

```python
from voice_recognizer import VoiceRecognizer

# إنشاء مثيل من النموذج
recognizer = VoiceRecognizer()

# تحليل ملف صوتي
results = recognizer.process_audio_file("audio.wav", language="ar")

# عرض النتائج
print("النص:", results['transcription']['whisper']['text'])
print("المشاعر:", results['emotion_analysis']['dominant_emotion'])
```

### استخدام معالج الصوت

```python
from audio_utils import AudioProcessor

# إنشاء معالج الصوت
processor = AudioProcessor()

# تحميل وتحسين الصوت
audio, sr = processor.load_audio("input.wav")
enhanced_audio = processor.enhance_audio(audio, sr)

# حفظ الصوت المحسن
processor.save_audio(enhanced_audio, "output.wav", sr)
```

## 🎯 أمثلة على الاستخدام

### 1. تحويل محاضرة إلى نص
```python
# تحميل محاضرة طويلة
results = recognizer.process_audio_file("lecture.wav", language="ar")
transcript = results['transcription']['whisper']['text']
print(transcript)
```

### 2. تحليل مشاعر مكالمة خدمة العملاء
```python
# تحليل مشاعر المكالمة
emotion_results = recognizer.analyze_emotion("customer_call.wav")
print(f"المشاعر السائدة: {emotion_results['dominant_emotion']}")
```

### 3. تحسين جودة تسجيل قديم
```python
# تحسين جودة الصوت
processor = AudioProcessor()
audio, sr = processor.load_audio("old_recording.wav")
enhanced = processor.enhance_audio(audio, sr)
processor.save_audio(enhanced, "enhanced_recording.wav", sr)
```

## 🛠️ التقنيات المستخدمة

### مكتبات الذكاء الاصطناعي
- **PyTorch**: إطار التعلم الآلي
- **Transformers**: نماذج الذكاء الاصطناعي
- **Whisper**: نموذج OpenAI للتعرف على الكلام
- **Librosa**: معالجة الصوت والتحليل

### واجهات المستخدم
- **Streamlit**: واجهة تفاعلية سريعة التطوير
- **Gradio**: واجهة سريعة للذكاء الاصطناعي
- **Plotly**: رسوم بيانية تفاعلية

### معالجة الصوت
- **SoundFile**: قراءة وكتابة ملفات الصوت
- **SciPy**: معالجة الإشارات
- **NoiseReduce**: إزالة الضوضاء
- **PyDub**: معالجة الصوت المتقدمة

## 📊 دعم صيغ الملفات

| الصيغة | القراءة | الكتابة | ملاحظات |
|--------|---------|---------|---------|
| WAV    | ✅      | ✅      | مستحسن |
| MP3    | ✅      | ❌      | يحتاج ffmpeg |
| M4A    | ✅      | ❌      | يحتاج ffmpeg |
| FLAC   | ✅      | ✅      | ضغط بدون فقدان |
| OGG    | ✅      | ✅      | مفتوح المصدر |

## ⚠️ ملاحظات مهمة

### الأداء
- **الذاكرة**: النماذج تحتاج 2-4GB من الذاكرة
- **المعالج**: يُفضل استخدام GPU لتسريع المعالجة
- **الوقت**: التحليل قد يستغرق بضع دقائق للملفات الكبيرة

### جودة النتائج
- **جودة الصوت**: كلما كانت جودة الصوت أفضل، كانت النتائج أدق
- **الضوضاء**: الضوضاء العالية تؤثر على دقة التحليل
- **اللغة**: تأكد من اختيار اللغة الصحيحة للتحليل

### المتطلبات التقنية
- **الميكروفون**: مطلوب للتسجيل المباشر
- **الاتصال بالإنترنت**: مطلوب لخدمات Google Speech
- **المساحة**: احتياطي 2GB على الأقل للنماذج

## 🐛 استكشاف الأخطاء

### مشاكل شائعة وحلولها

**1. خطأ في تحميل النماذج**
```
الحل: تأكد من تثبيت جميع المتطلبات
pip install -r requirements.txt
```

**2. خطأ في تسجيل الصوت**
```
الحل: تأكد من وجود ميكروفون متصل
وتأكد من صلاحيات الوصول للميكروفون
```

**3. خطأ في رفع الملفات**
```
الحل: تأكد من صيغة الملف المدعومة
ودقة أن الملف غير تالف
```

**4. بطء في التحليل**
```
الحل: استخدم ملفات أصغر أو قم بتقليل جودة الصوت
```

## 🤝 المساهمة

نرحب بمساهماتكم! يمكنكم:

1. **الإبلاغ عن الأخطاء** عبر Issues
2. **اقتراح ميزات جديدة** عبر Discussions
3. **إرسال Pull Requests** للتحسينات
4. **تحسين الوثائق** والترجمة

## 📄 الترخيص

هذا المشروع مرخص تحت رخصة MIT. راجع ملف `LICENSE` للتفاصيل.

## 📞 الدعم

- **المشاكل التقنية**: افتح Issue في GitHub
- **الأسئلة العامة**: استخدم Discussions
- **الطلبات المخصصة**: تواصل معنا

## 🔄 التحديثات المستقبلية

### الميزات المخططة
- [ ] دعم لغات إضافية
- [ ] تحسين دقة النماذج
- [ ] واجهة موبايل
- [ ] API للاستخدام الخارجي
- [ ] تحليل المشاعر المتقدم
- [ ] كشف المتحدثين المتعددين
- [ ] تصدير النتائج بصيغ مختلفة

---

**تم تطوير هذا المشروع بحب ❤️ لخدمة المجتمع العربي في مجال الذكاء الاصطناعي**

*آخر تحديث: ديسمبر 2024*