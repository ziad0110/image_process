# 🎤 مشروع تمييز الأصوات المتقدم

مشروع شامل لتمييز الأصوات باستخدام الذكاء الاصطناعي مع واجهات تفاعلية متقدمة.

## 🌟 الميزات الرئيسية

### 🎯 تمييز الأصوات
- **دعم متعدد الطرق**: Whisper، Wav2Vec2، SpeechRecognition
- **دعم متعدد اللغات**: العربية، الإنجليزية، والعديد من اللغات الأخرى
- **دقة عالية**: استخدام أحدث نماذج الذكاء الاصطناعي
- **معالجة متقدمة**: إزالة الضوضاء وتحسين جودة الصوت

### 🏷️ تصنيف الأصوات
- **تصنيف الجنس**: تمييز الأصوات الذكورية والأنثوية
- **تصنيف العواطف**: تحديد الحالة العاطفية (سعيد، حزين، غاضب، محايد)
- **تصنيف العمر**: تحديد الفئة العمرية للمتحدث
- **تصنيف اللغة**: تحديد لغة الكلام

### 📊 تحليل الصوت المتقدم
- **استخراج الخصائص**: MFCC، الطيف، الطاقة، وغيرها
- **الرسوم البيانية**: عرض الموجات الصوتية والطيف
- **الإحصائيات**: تحليل شامل لخصائص الصوت
- **التصور التفاعلي**: رسوم بيانية تفاعلية باستخدام Plotly

### 🖥️ واجهة تفاعلية
- **واجهة سهلة الاستخدام**: تصميم عربي أنيق ومتجاوب
- **رفع الملفات**: دعم صيغ صوتية متعددة (WAV، MP3، M4A، FLAC، OGG)
- **النتائج الفورية**: عرض النتائج مع مستوى الثقة
- **إدارة الملفات**: تنظيم وإدارة الملفات المرفوعة

## 🛠️ التقنيات المستخدمة

### الذكاء الاصطناعي والتعلم الآلي
- **PyTorch**: إطار عمل الذكاء الاصطناعي
- **Transformers**: نماذج معالجة اللغة الطبيعية
- **Whisper**: نموذج تمييز الأصوات من OpenAI
- **Wav2Vec2**: نموذج تمييز الأصوات من Facebook
- **Scikit-learn**: خوارزميات التعلم الآلي

### معالجة الصوت
- **Librosa**: مكتبة معالجة الصوت المتقدمة
- **SoundFile**: قراءة وكتابة الملفات الصوتية
- **PyDub**: معالجة وتحرير الصوت
- **SpeechRecognition**: تمييز الأصوات الأساسي

### الواجهة والتصور
- **Streamlit**: إطار عمل الواجهات التفاعلية
- **Plotly**: الرسوم البيانية التفاعلية
- **Matplotlib**: الرسوم البيانية الثابتة
- **Pandas**: معالجة البيانات

## 📋 متطلبات النظام

### المتطلبات الأساسية
- Python 3.8 أو أحدث
- 4 GB RAM على الأقل
- 2 GB مساحة تخزين فارغة

### المتطلبات الاختيارية
- GPU مع دعم CUDA (لتسريع التدريب)
- ميكروفون (للتسجيل المباشر)

## 🚀 التثبيت والتشغيل

### 1. استنساخ المشروع
```bash
git clone <repository-url>
cd voice_recognition_project
```

### 2. إنشاء بيئة افتراضية (مستحسن)
```bash
python -m venv venv
source venv/bin/activate  # على Linux/Mac
# أو
venv\\Scripts\\activate  # على Windows
```

### 3. تثبيت المتطلبات
```bash
pip install -r requirements.txt
```

### 4. إعداد المشروع
```bash
python run.py --mode setup
```

### 5. تشغيل التطبيق
```bash
python run.py --mode app
```

سيتم فتح التطبيق في المتصفح على العنوان: `http://localhost:8501`

## 📖 دليل الاستخدام

### تمييز الأصوات
1. **تحميل النماذج**: اضغط على "تحميل النماذج" في الشريط الجانبي
2. **رفع الملف**: اختر ملف صوتي من جهازك
3. **اختيار الإعدادات**: حدد طريقة التمييز واللغة
4. **بدء التمييز**: اضغط على "ابدأ التمييز"
5. **عرض النتائج**: استعرض النص المميز والتحليلات

### تصنيف الأصوات
1. **اختيار الملف**: اختر ملف من الملفات المرفوعة
2. **بدء التصنيف**: اضغط على "ابدأ التصنيف"
3. **عرض النتائج**: استعرض التصنيف المتوقع ومستوى الثقة

### تحليل الصوت
1. **اختيار الملف**: اختر ملف للتحليل
2. **عرض الخصائص**: استعرض الخصائص المستخرجة
3. **الرسوم البيانية**: شاهد الموجات الصوتية والطيف

## 🤖 تدريب النماذج

### تدريب نموذج جديد
```bash
python run.py --mode train
```

### تدريب مخصص
```python
from src.training_utils import ModelTrainer, DatasetManager

# إعداد مدير البيانات
data_manager = DatasetManager()

# إعداد المدرب
trainer = ModelTrainer(data_manager)

# تدريب نموذج تصنيف الجنس
results = trainer.train_classification_model("gender", "random_forest")
print(results)
```

## 📁 هيكل المشروع

```
voice_recognition_project/
├── src/                          # الكود المصدري
│   ├── voice_recognizer.py      # نظام تمييز الأصوات
│   ├── voice_classifier.py      # نظام تصنيف الأصوات
│   └── training_utils.py        # أدوات التدريب
├── models/                       # النماذج المدربة
├── data/                         # البيانات
│   ├── raw/                     # البيانات الخام
│   ├── processed/               # البيانات المعالجة
│   ├── train/                   # بيانات التدريب
│   ├── test/                    # بيانات الاختبار
│   └── validation/              # بيانات التحقق
├── uploads/                      # الملفات المرفوعة
├── app.py                       # التطبيق الرئيسي
├── run.py                       # ملف التشغيل
├── requirements.txt             # المتطلبات
└── README.md                    # هذا الملف
```

## 🔧 التخصيص والتطوير

### إضافة طريقة تمييز جديدة
```python
class CustomVoiceRecognizer(VoiceRecognizer):
    def recognize_with_custom_model(self, audio_path: str) -> str:
        # تنفيذ طريقة التمييز المخصصة
        pass
```

### إضافة نوع تصنيف جديد
```python
# في voice_classifier.py
self.supported_classifications["custom_type"] = ["class1", "class2", "class3"]
```

### تخصيص الواجهة
يمكن تخصيص الواجهة من خلال تعديل ملف `app.py` وإضافة CSS مخصص.

## 🐛 استكشاف الأخطاء

### مشاكل شائعة

#### خطأ في تحميل النماذج
```bash
# تأكد من تثبيت PyTorch
pip install torch torchaudio

# تحقق من اتصال الإنترنت لتحميل النماذج
```

#### خطأ في معالجة الصوت
```bash
# تثبيت مكتبات الصوت
pip install librosa soundfile pyaudio
```

#### مشاكل في الواجهة
```bash
# تحديث Streamlit
pip install --upgrade streamlit
```

### سجلات الأخطاء
يمكن العثور على سجلات الأخطاء في:
- سجل Streamlit: `streamlit.log`
- سجل Python: في وحدة التحكم

## 📊 الأداء والتحسين

### تحسين الأداء
- استخدام GPU لتسريع التدريب
- تحسين حجم الملفات الصوتية
- استخدام نماذج أصغر للاستخدام السريع

### قياس الدقة
```python
# تقييم النموذج
results = trainer.evaluate_model("gender")
print(f"الدقة الإجمالية: {results['overall_accuracy']:.3f}")
```

## 🤝 المساهمة

نرحب بالمساهمات! يرجى:
1. Fork المشروع
2. إنشاء فرع للميزة الجديدة
3. إجراء التغييرات
4. إرسال Pull Request

## 📄 الترخيص

هذا المشروع مرخص تحت رخصة MIT. راجع ملف `LICENSE` للتفاصيل.

## 📞 الدعم والمساعدة

- **المشاكل التقنية**: افتح issue في GitHub
- **الأسئلة العامة**: استخدم منتدى المناقشات
- **الميزات الجديدة**: اقترح في قسم الأفكار

## 🔮 التطويرات المستقبلية

- [ ] دعم المزيد من اللغات
- [ ] تحسين دقة التمييز
- [ ] إضافة تصنيفات جديدة
- [ ] واجهة تطبيق جوال
- [ ] API للاستخدام الخارجي
- [ ] دعم التسجيل المباشر
- [ ] تحليل المشاعر المتقدم

---

**تم تطوير هذا المشروع بحب ❤️ لخدمة المجتمع العربي في مجال الذكاء الاصطناعي**