"""
ÙˆØ§Ø¬Ù‡Ø© ØªÙØ§Ø¹Ù„ÙŠØ© Ù„ØªÙ…ÙŠÙŠØ² Ø§Ù„Ø£ØµÙˆØ§Øª
Interactive Voice Recognition Interface
"""

import streamlit as st
import os
import sys
import time
import numpy as np
import librosa
import matplotlib.pyplot as plt
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import pandas as pd
from datetime import datetime
import json

# Ø¥Ø¶Ø§ÙØ© Ù…Ø³Ø§Ø± src Ø¥Ù„Ù‰ Python path
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from voice_recognizer import VoiceRecognizer
from voice_classifier import VoiceClassifier

# Ø¥Ø¹Ø¯Ø§Ø¯ ØµÙØ­Ø© Streamlit
st.set_page_config(
    page_title="Ù†Ø¸Ø§Ù… ØªÙ…ÙŠÙŠØ² Ø§Ù„Ø£ØµÙˆØ§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…",
    page_icon="ğŸ¤",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS Ù…Ø®ØµØµ Ù„Ù„ÙˆØ§Ø¬Ù‡Ø©
st.markdown("""
<style>
    .main-header {
        text-align: center;
        color: #1f77b4;
        font-size: 2.5rem;
        margin-bottom: 2rem;
    }
    .feature-box {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 10px;
        margin: 1rem 0;
        border-left: 4px solid #1f77b4;
    }
    .result-box {
        background-color: #e8f4fd;
        padding: 1rem;
        border-radius: 10px;
        margin: 1rem 0;
        border: 1px solid #1f77b4;
    }
    .error-box {
        background-color: #ffe6e6;
        padding: 1rem;
        border-radius: 10px;
        margin: 1rem 0;
        border: 1px solid #ff4444;
    }
    .success-box {
        background-color: #e6ffe6;
        padding: 1rem;
        border-radius: 10px;
        margin: 1rem 0;
        border: 1px solid #44ff44;
    }
</style>
""", unsafe_allow_html=True)

# ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø¬Ù„Ø³Ø©
if 'voice_recognizer' not in st.session_state:
    st.session_state.voice_recognizer = None
if 'voice_classifier' not in st.session_state:
    st.session_state.voice_classifier = None
if 'uploaded_files' not in st.session_state:
    st.session_state.uploaded_files = []

def initialize_models():
    """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬"""
    try:
        if st.session_state.voice_recognizer is None:
            with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ù†Ù…Ø§Ø°Ø¬ ØªÙ…ÙŠÙŠØ² Ø§Ù„Ø£ØµÙˆØ§Øª..."):
                st.session_state.voice_recognizer = VoiceRecognizer()
        
        if st.session_state.voice_classifier is None:
            st.session_state.voice_classifier = VoiceClassifier()
            
        return True
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬: {e}")
        return False

def plot_audio_waveform(audio_path: str):
    """Ø±Ø³Ù… Ø´ÙƒÙ„ Ø§Ù„Ù…ÙˆØ¬Ø© Ø§Ù„ØµÙˆØªÙŠØ©"""
    try:
        audio, sr = librosa.load(audio_path)
        time = np.linspace(0, len(audio) / sr, len(audio))
        
        fig = go.Figure()
        fig.add_trace(go.Scatter(
            x=time,
            y=audio,
            mode='lines',
            name='Ø§Ù„Ù…ÙˆØ¬Ø© Ø§Ù„ØµÙˆØªÙŠØ©',
            line=dict(color='#1f77b4', width=1)
        ))
        
        fig.update_layout(
            title="Ø´ÙƒÙ„ Ø§Ù„Ù…ÙˆØ¬Ø© Ø§Ù„ØµÙˆØªÙŠØ©",
            xaxis_title="Ø§Ù„ÙˆÙ‚Øª (Ø«Ø§Ù†ÙŠØ©)",
            yaxis_title="Ø§Ù„Ø³Ø¹Ø©",
            height=400,
            showlegend=True
        )
        
        return fig
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø±Ø³Ù… Ø§Ù„Ù…ÙˆØ¬Ø© Ø§Ù„ØµÙˆØªÙŠØ©: {e}")
        return None

def plot_spectrogram(audio_path: str):
    """Ø±Ø³Ù… Ø§Ù„Ø·ÙŠÙ Ø§Ù„ØµÙˆØªÙŠ"""
    try:
        audio, sr = librosa.load(audio_path)
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø·ÙŠÙ Ø§Ù„ØµÙˆØªÙŠ
        stft = librosa.stft(audio)
        magnitude = np.abs(stft)
        log_magnitude = librosa.amplitude_to_db(magnitude)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø±Ø³Ù…
        fig = go.Figure(data=go.Heatmap(
            z=log_magnitude,
            colorscale='Viridis',
            name='Ø§Ù„Ø·ÙŠÙ Ø§Ù„ØµÙˆØªÙŠ'
        ))
        
        fig.update_layout(
            title="Ø§Ù„Ø·ÙŠÙ Ø§Ù„ØµÙˆØªÙŠ",
            xaxis_title="Ø§Ù„ÙˆÙ‚Øª",
            yaxis_title="Ø§Ù„ØªØ±Ø¯Ø¯",
            height=400
        )
        
        return fig
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø±Ø³Ù… Ø§Ù„Ø·ÙŠÙ Ø§Ù„ØµÙˆØªÙŠ: {e}")
        return None

def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„ØªØ·Ø¨ÙŠÙ‚"""
    
    # Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
    st.markdown('<h1 class="main-header">ğŸ¤ Ù†Ø¸Ø§Ù… ØªÙ…ÙŠÙŠØ² Ø§Ù„Ø£ØµÙˆØ§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…</h1>', unsafe_allow_html=True)
    
    # Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ
    with st.sidebar:
        st.header("âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
        
        # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
        if st.button("ğŸ”„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬"):
            if initialize_models():
                st.success("ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¨Ù†Ø¬Ø§Ø­!")
            else:
                st.error("ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬")
        
        st.markdown("---")
        
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªÙ…ÙŠÙŠØ²
        st.subheader("ğŸ¯ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªÙ…ÙŠÙŠØ²")
        recognition_method = st.selectbox(
            "Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªÙ…ÙŠÙŠØ²",
            ["whisper", "wav2vec2", "speech_recognition"],
            help="Ø§Ø®ØªØ± Ø·Ø±ÙŠÙ‚Ø© ØªÙ…ÙŠÙŠØ² Ø§Ù„Ø£ØµÙˆØ§Øª"
        )
        
        language = st.selectbox(
            "Ø§Ù„Ù„ØºØ©",
            ["ar", "en", "auto"],
            help="Ù„ØºØ© Ø§Ù„ØµÙˆØª Ø§Ù„Ù…Ø±Ø§Ø¯ ØªÙ…ÙŠÙŠØ²Ù‡"
        )
        
        st.markdown("---")
        
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØµÙ†ÙŠÙ
        st.subheader("ğŸ·ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØµÙ†ÙŠÙ")
        classification_type = st.selectbox(
            "Ù†ÙˆØ¹ Ø§Ù„ØªØµÙ†ÙŠÙ",
            ["gender", "emotion", "age_group", "language"],
            help="Ù†ÙˆØ¹ ØªØµÙ†ÙŠÙ Ø§Ù„ØµÙˆØª"
        )
    
    # Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸ¤ ØªÙ…ÙŠÙŠØ² Ø§Ù„Ø£ØµÙˆØ§Øª", 
        "ğŸ·ï¸ ØªØµÙ†ÙŠÙ Ø§Ù„Ø£ØµÙˆØ§Øª", 
        "ğŸ“Š ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØª", 
        "ğŸ“ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ù„ÙØ§Øª",
        "â„¹ï¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"
    ])
    
    with tab1:
        st.header("ğŸ¤ ØªÙ…ÙŠÙŠØ² Ø§Ù„Ø£ØµÙˆØ§Øª")
        
        # Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª
        uploaded_file = st.file_uploader(
            "Ø§Ø®ØªØ± Ù…Ù„Ù ØµÙˆØªÙŠ",
            type=['wav', 'mp3', 'm4a', 'flac', 'ogg'],
            help="ÙŠÙ…ÙƒÙ†Ùƒ Ø±ÙØ¹ Ù…Ù„ÙØ§Øª ØµÙˆØªÙŠØ© Ø¨ØµÙŠØº Ù…Ø®ØªÙ„ÙØ©"
        )
        
        if uploaded_file is not None:
            # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù
            timestamp = int(time.time())
            file_path = f"uploads/audio_{timestamp}_{uploaded_file.name}"
            os.makedirs("uploads", exist_ok=True)
            
            with open(file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            
            st.session_state.uploaded_files.append(file_path)
            
            # Ø¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù„Ù
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù", uploaded_file.name)
            with col2:
                st.metric("Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù", f"{uploaded_file.size / 1024:.1f} KB")
            with col3:
                st.metric("Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù", uploaded_file.type)
            
            # ØªÙ…ÙŠÙŠØ² Ø§Ù„ØµÙˆØª
            if st.button("ğŸ¯ Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªÙ…ÙŠÙŠØ²", type="primary"):
                if st.session_state.voice_recognizer is None:
                    st.error("ÙŠØ±Ø¬Ù‰ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø£ÙˆÙ„Ø§Ù‹ Ù…Ù† Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ")
                else:
                    with st.spinner("Ø¬Ø§Ø±ÙŠ ØªÙ…ÙŠÙŠØ² Ø§Ù„ØµÙˆØª..."):
                        results = st.session_state.voice_recognizer.recognize_audio(
                            file_path, method=recognition_method
                        )
                    
                    if "error" in results:
                        st.markdown(f'<div class="error-box">âŒ Ø®Ø·Ø£: {results["error"]}</div>', unsafe_allow_html=True)
                    else:
                        st.markdown('<div class="success-box">âœ… ØªÙ… ØªÙ…ÙŠÙŠØ² Ø§Ù„ØµÙˆØª Ø¨Ù†Ø¬Ø§Ø­!</div>', unsafe_allow_html=True)
                        
                        # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
                        col1, col2 = st.columns([2, 1])
                        
                        with col1:
                            st.subheader("ğŸ“ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ù…ÙŠØ²")
                            st.text_area("", results.get("text", ""), height=150)
                        
                        with col2:
                            st.subheader("ğŸ“Š ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
                            if "language" in results:
                                st.metric("Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…ÙƒØªØ´ÙØ©", results["language"])
                            if "confidence" in results:
                                st.metric("Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©", f"{results['confidence']:.2f}")
                            st.metric("Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªÙ…ÙŠÙŠØ²", results["method"])
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ©
            st.subheader("ğŸ“ˆ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØª")
            
            col1, col2 = st.columns(2)
            
            with col1:
                waveform_fig = plot_audio_waveform(file_path)
                if waveform_fig:
                    st.plotly_chart(waveform_fig, use_container_width=True)
            
            with col2:
                spectrogram_fig = plot_spectrogram(file_path)
                if spectrogram_fig:
                    st.plotly_chart(spectrogram_fig, use_container_width=True)
    
    with tab2:
        st.header("ğŸ·ï¸ ØªØµÙ†ÙŠÙ Ø§Ù„Ø£ØµÙˆØ§Øª")
        
        if st.session_state.voice_classifier is None:
            st.warning("ÙŠØ±Ø¬Ù‰ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø£ÙˆÙ„Ø§Ù‹ Ù…Ù† Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ")
        else:
            # ØªØµÙ†ÙŠÙ Ù…Ù„Ù ÙˆØ§Ø­Ø¯
            st.subheader("ØªØµÙ†ÙŠÙ Ù…Ù„Ù ØµÙˆØªÙŠ")
            
            if st.session_state.uploaded_files:
                selected_file = st.selectbox(
                    "Ø§Ø®ØªØ± Ù…Ù„Ù Ù„Ù„ØªØµÙ†ÙŠÙ",
                    st.session_state.uploaded_files
                )
                
                if st.button("ğŸ·ï¸ Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØµÙ†ÙŠÙ"):
                    with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØµÙ†ÙŠÙ Ø§Ù„ØµÙˆØª..."):
                        results = st.session_state.voice_classifier.predict(selected_file)
                    
                    if "error" in results:
                        st.markdown(f'<div class="error-box">âŒ Ø®Ø·Ø£: {results["error"]}</div>', unsafe_allow_html=True)
                    else:
                        st.markdown('<div class="success-box">âœ… ØªÙ… ØªØµÙ†ÙŠÙ Ø§Ù„ØµÙˆØª Ø¨Ù†Ø¬Ø§Ø­!</div>', unsafe_allow_html=True)
                        
                        # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.subheader("ğŸ¯ Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹")
                            st.metric("Ø§Ù„Ù†ØªÙŠØ¬Ø©", results["prediction"])
                            st.metric("Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©", f"{results['confidence']:.2f}")
                        
                        with col2:
                            st.subheader("ğŸ“Š Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª Ø§Ù„ØªØµÙ†ÙŠÙ")
                            prob_df = pd.DataFrame(
                                list(results["probabilities"].items()),
                                columns=["Ø§Ù„ØªØµÙ†ÙŠÙ", "Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ©"]
                            )
                            prob_df["Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ©"] = prob_df["Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ©"].round(3)
                            st.dataframe(prob_df, use_container_width=True)
            
            # ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø¬Ø¯ÙŠØ¯
            st.subheader("ğŸ¤– ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø¬Ø¯ÙŠØ¯")
            st.info("Ù‡Ø°Ù‡ Ø§Ù„Ù…ÙŠØ²Ø© ØªØªØ·Ù„Ø¨ Ù…Ù„ÙØ§Øª ØªØ¯Ø±ÙŠØ¨ Ù…ØµÙ†ÙØ© Ù…Ø³Ø¨Ù‚Ø§Ù‹")
    
    with tab3:
        st.header("ğŸ“Š ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…")
        
        if st.session_state.uploaded_files:
            selected_file = st.selectbox(
                "Ø§Ø®ØªØ± Ù…Ù„Ù Ù„Ù„ØªØ­Ù„ÙŠÙ„",
                st.session_state.uploaded_files,
                key="analysis_file"
            )
            
            if selected_file:
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø®ØµØ§Ø¦Øµ Ø§Ù„ØµÙˆØª
                if st.session_state.voice_recognizer:
                    features = st.session_state.voice_recognizer.get_audio_features(selected_file)
                    
                    if features:
                        st.subheader("ğŸ” Ø®ØµØ§Ø¦Øµ Ø§Ù„ØµÙˆØª")
                        
                        col1, col2, col3 = st.columns(3)
                        
                        with col1:
                            st.metric("Ø§Ù„Ù…Ø¯Ø© (Ø«Ø§Ù†ÙŠØ©)", f"{features['duration']:.2f}")
                            st.metric("Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø¹ÙŠÙ†Ø©", f"{features['sample_rate']}")
                        
                        with col2:
                            st.metric("Ø·Ø§Ù‚Ø© RMS", f"{features['rms_energy']:.4f}")
                            st.metric("Ù…Ø¹Ø¯Ù„ Ø¹Ø¨ÙˆØ± Ø§Ù„ØµÙØ±", f"{features['zero_crossing_rate']:.4f}")
                        
                        with col3:
                            st.metric("Ø§Ù„Ù…Ø±ÙƒØ² Ø§Ù„Ø·ÙŠÙÙŠ", f"{features['spectral_centroid']:.2f}")
                            st.metric("Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ø·ÙŠÙÙŠ", f"{features['spectral_rolloff']:.2f}")
                        
                        # Ø±Ø³Ù… Ù…Ø¹Ø§Ù…Ù„Ø§Øª MFCC
                        st.subheader("ğŸµ Ù…Ø¹Ø§Ù…Ù„Ø§Øª MFCC")
                        mfcc_data = features['mfcc']
                        fig = go.Figure(data=go.Bar(
                            x=list(range(len(mfcc_data))),
                            y=mfcc_data,
                            name='MFCC'
                        ))
                        fig.update_layout(
                            title="Ù…Ø¹Ø§Ù…Ù„Ø§Øª MFCC",
                            xaxis_title="Ø§Ù„Ù…Ø¹Ø§Ù…Ù„",
                            yaxis_title="Ø§Ù„Ù‚ÙŠÙ…Ø©",
                            height=400
                        )
                        st.plotly_chart(fig, use_container_width=True)
    
    with tab4:
        st.header("ğŸ“ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ù„ÙØ§Øª")
        
        if st.session_state.uploaded_files:
            st.subheader("Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø©")
            
            for i, file_path in enumerate(st.session_state.uploaded_files):
                col1, col2, col3 = st.columns([3, 1, 1])
                
                with col1:
                    st.text(file_path)
                
                with col2:
                    if st.button(f"ğŸ—‘ï¸ Ø­Ø°Ù", key=f"delete_{i}"):
                        try:
                            os.remove(file_path)
                            st.session_state.uploaded_files.remove(file_path)
                            st.rerun()
                        except:
                            st.error("Ø®Ø·Ø£ ÙÙŠ Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù")
                
                with col3:
                    if st.button(f"ğŸ“Š ØªØ­Ù„ÙŠÙ„", key=f"analyze_{i}"):
                        st.session_state.selected_file = file_path
                        st.rerun()
        else:
            st.info("Ù„Ù… ÙŠØªÙ… Ø±ÙØ¹ Ø£ÙŠ Ù…Ù„ÙØ§Øª Ø¨Ø¹Ø¯")
    
    with tab5:
        st.header("â„¹ï¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø´Ø±ÙˆØ¹")
        
        st.markdown("""
        <div class="feature-box">
            <h3>ğŸ¯ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©</h3>
            <ul>
                <li><strong>ØªÙ…ÙŠÙŠØ² Ø§Ù„Ø£ØµÙˆØ§Øª:</strong> Ø¯Ø¹Ù… Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ø·Ø±Ù‚ (Whisper, Wav2Vec2, SpeechRecognition)</li>
                <li><strong>ØªØµÙ†ÙŠÙ Ø§Ù„Ø£ØµÙˆØ§Øª:</strong> ØªØµÙ†ÙŠÙ Ø­Ø³Ø¨ Ø§Ù„Ø¬Ù†Ø³ØŒ Ø§Ù„Ø¹Ø§Ø·ÙØ©ØŒ Ø§Ù„Ø¹Ù…Ø±ØŒ ÙˆØ§Ù„Ù„ØºØ©</li>
                <li><strong>ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØª:</strong> Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø®ØµØ§Ø¦Øµ Ù…ØªÙ‚Ø¯Ù…Ø© ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø·ÙŠÙ</li>
                <li><strong>ÙˆØ§Ø¬Ù‡Ø© ØªÙØ§Ø¹Ù„ÙŠØ©:</strong> ÙˆØ§Ø¬Ù‡Ø© Ø³Ù‡Ù„Ø© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¹ Ø±Ø³ÙˆÙ… Ø¨ÙŠØ§Ù†ÙŠØ©</li>
                <li><strong>Ø¯Ø¹Ù… Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù„ØºØ§Øª:</strong> Ø¯Ø¹Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© ÙˆÙ„ØºØ§Øª Ø£Ø®Ø±Ù‰</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown("""
        <div class="feature-box">
            <h3>ğŸ› ï¸ Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©</h3>
            <ul>
                <li><strong>Python:</strong> Ù„ØºØ© Ø§Ù„Ø¨Ø±Ù…Ø¬Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©</li>
                <li><strong>Streamlit:</strong> ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠØ©</li>
                <li><strong>PyTorch:</strong> Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ</li>
                <li><strong>Librosa:</strong> Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª</li>
                <li><strong>Scikit-learn:</strong> Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ</li>
                <li><strong>Plotly:</strong> Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ© Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠØ©</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown("""
        <div class="feature-box">
            <h3>ğŸ“‹ ÙƒÙŠÙÙŠØ© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…</h3>
            <ol>
                <li>Ø§Ø¶ØºØ· Ø¹Ù„Ù‰ "ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬" ÙÙŠ Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ</li>
                <li>Ø§Ø®ØªØ± Ù…Ù„Ù ØµÙˆØªÙŠ Ù…Ù† Ø¬Ù‡Ø§Ø²Ùƒ</li>
                <li>Ø§Ø®ØªØ± Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªÙ…ÙŠÙŠØ² ÙˆØ§Ù„Ù„ØºØ©</li>
                <li>Ø§Ø¶ØºØ· Ø¹Ù„Ù‰ "Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªÙ…ÙŠÙŠØ²"</li>
                <li>Ø§Ø³ØªÙ…ØªØ¹ Ø¨Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª!</li>
            </ol>
        </div>
        """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()