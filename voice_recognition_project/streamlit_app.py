"""
ÙˆØ§Ø¬Ù‡Ø© Streamlit Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠØ© Ù„ØªÙ…ÙŠÙŠØ² Ø§Ù„Ø£ØµÙˆØ§Øª
Interactive Streamlit Interface for Voice Recognition
"""

import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
import pandas as pd
import numpy as np
import librosa
import soundfile as sf
import tempfile
import os
from voice_recognizer import VoiceRecognizer
import time

# Ø¥Ø¹Ø¯Ø§Ø¯ ØµÙØ­Ø© Streamlit
st.set_page_config(
    page_title="ğŸ¤ Ù†Ø¸Ø§Ù… ØªÙ…ÙŠÙŠØ² Ø§Ù„Ø£ØµÙˆØ§Øª Ø§Ù„Ø°ÙƒÙŠ",
    page_icon="ğŸ¤",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS Ù…Ø®ØµØµ Ù„Ù„ÙˆØ§Ø¬Ù‡Ø©
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
    }
    .feature-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1.5rem;
        border-radius: 10px;
        color: white;
        margin: 1rem 0;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    .result-box {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #28a745;
        margin: 1rem 0;
    }
    .metric-card {
        background: white;
        padding: 1rem;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        text-align: center;
    }
</style>
""", unsafe_allow_html=True)

def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„ØªØ·Ø¨ÙŠÙ‚"""
    
    # Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
    st.markdown('<h1 class="main-header">ğŸ¤ Ù†Ø¸Ø§Ù… ØªÙ…ÙŠÙŠØ² Ø§Ù„Ø£ØµÙˆØ§Øª Ø§Ù„Ø°ÙƒÙŠ</h1>', unsafe_allow_html=True)
    
    # Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ
    with st.sidebar:
        st.markdown("## âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
        
        # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù„ØºØ©
        language = st.selectbox(
            "ğŸŒ Ø§Ø®ØªØ± Ø§Ù„Ù„ØºØ©:",
            ["ar", "en", "fr", "es", "de", "it"],
            format_func=lambda x: {
                "ar": "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
                "en": "Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©", 
                "fr": "Ø§Ù„ÙØ±Ù†Ø³ÙŠØ©",
                "es": "Ø§Ù„Ø¥Ø³Ø¨Ø§Ù†ÙŠØ©",
                "de": "Ø§Ù„Ø£Ù„Ù…Ø§Ù†ÙŠØ©",
                "it": "Ø§Ù„Ø¥ÙŠØ·Ø§Ù„ÙŠØ©"
            }[x]
        )
        
        # Ù…Ø¯Ø© Ø§Ù„ØªØ³Ø¬ÙŠÙ„
        duration = st.slider("â±ï¸ Ù…Ø¯Ø© Ø§Ù„ØªØ³Ø¬ÙŠÙ„ (Ø«ÙˆØ§Ù†ÙŠ):", 1, 30, 5)
        
        # Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„
        st.markdown("## ğŸ” Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„")
        analyze_emotion = st.checkbox("ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±", value=True)
        extract_features = st.checkbox("Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø®ØµØ§Ø¦Øµ", value=True)
        speaker_analysis = st.checkbox("ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªØ­Ø¯Ø«", value=True)
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø«ÙŠÙ„ Ù…Ù† ÙØ¦Ø© ØªÙ…ÙŠÙŠØ² Ø§Ù„Ø£ØµÙˆØ§Øª
    if 'recognizer' not in st.session_state:
        with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬... Ù‚Ø¯ ÙŠØ³ØªØºØ±Ù‚ Ù‡Ø°Ø§ Ø¨Ø¶Ø¹ Ø¯Ù‚Ø§Ø¦Ù‚"):
            st.session_state.recognizer = VoiceRecognizer()
    
    # Ø§Ù„ØªØ¨ÙˆÙŠØ¨Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ™ï¸ ØªØ³Ø¬ÙŠÙ„ Ù…Ø¨Ø§Ø´Ø±", "ğŸ“ Ø±ÙØ¹ Ù…Ù„Ù", "ğŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…", "â„¹ï¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"])
    
    with tab1:
        st.markdown("## ğŸ™ï¸ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙˆØª Ø§Ù„Ù…Ø¨Ø§Ø´Ø±")
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            if st.button("ğŸ”´ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ³Ø¬ÙŠÙ„", type="primary", use_container_width=True):
                with st.spinner(f"Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ù„Ù…Ø¯Ø© {duration} Ø«Ø§Ù†ÙŠØ©..."):
                    audio_file = st.session_state.recognizer.record_audio(duration)
                    
                    if audio_file:
                        st.success("ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¨Ù†Ø¬Ø§Ø­!")
                        st.session_state.recorded_audio = audio_file
                        
                        # ØªØ´ØºÙŠÙ„ Ø§Ù„ØµÙˆØª Ø§Ù„Ù…Ø³Ø¬Ù„
                        st.audio(audio_file)
                    else:
                        st.error("ÙØ´Ù„ ÙÙŠ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙˆØª")
        
        with col2:
            if 'recorded_audio' in st.session_state:
                if st.button("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØª Ø§Ù„Ù…Ø³Ø¬Ù„", use_container_width=True):
                    analyze_audio(st.session_state.recorded_audio, language, 
                                analyze_emotion, extract_features, speaker_analysis)
    
    with tab2:
        st.markdown("## ğŸ“ Ø±ÙØ¹ Ù…Ù„Ù ØµÙˆØªÙŠ")
        
        uploaded_file = st.file_uploader(
            "Ø§Ø®ØªØ± Ù…Ù„Ù ØµÙˆØªÙŠ",
            type=['wav', 'mp3', 'm4a', 'flac', 'ogg'],
            help="ÙŠØ¯Ø¹Ù… Ø§Ù„Ù…Ù„ÙØ§Øª: WAV, MP3, M4A, FLAC, OGG"
        )
        
        if uploaded_file is not None:
            # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª
            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
                tmp_file.write(uploaded_file.read())
                temp_audio_path = tmp_file.name
            
            st.success("ØªÙ… Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù Ø¨Ù†Ø¬Ø§Ø­!")
            st.audio(uploaded_file)
            
            if st.button("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø±ÙÙˆØ¹", type="primary"):
                analyze_audio(temp_audio_path, language, 
                            analyze_emotion, extract_features, speaker_analysis)
    
    with tab3:
        st.markdown("## ğŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…")
        
        if 'analysis_results' in st.session_state:
            display_advanced_analysis(st.session_state.analysis_results)
        else:
            st.info("Ù‚Ù… Ø¨ØªØ³Ø¬ÙŠÙ„ Ø£Ùˆ Ø±ÙØ¹ Ù…Ù„Ù ØµÙˆØªÙŠ Ø£ÙˆÙ„Ø§Ù‹ Ù„Ø±Ø¤ÙŠØ© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…")
    
    with tab4:
        display_project_info()

def analyze_audio(audio_file, language, analyze_emotion, extract_features, speaker_analysis):
    """ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØª ÙˆØ¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬"""
    
    with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØª... Ù‡Ø°Ø§ Ù‚Ø¯ ÙŠØ³ØªØºØ±Ù‚ Ø¨Ø¶Ø¹ Ø¯Ù‚Ø§Ø¦Ù‚"):
        results = st.session_state.recognizer.process_audio_file(audio_file, language)
        st.session_state.analysis_results = results
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    st.markdown("## ğŸ“‹ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„")
    
    # Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù†Øµ
    if 'transcription' in results:
        st.markdown("### ğŸ“ Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù†Øµ")
        
        transcription_results = results['transcription']
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if 'whisper' in transcription_results:
                st.markdown("**Whisper:**")
                st.markdown(f'<div class="result-box">{transcription_results["whisper"]["text"]}</div>', 
                           unsafe_allow_html=True)
        
        with col2:
            if 'google' in transcription_results:
                st.markdown("**Google Speech:**")
                st.markdown(f'<div class="result-box">{transcription_results["google"]["text"]}</div>', 
                           unsafe_allow_html=True)
        
        with col3:
            if 'sphinx' in transcription_results:
                st.markdown("**Sphinx:**")
                st.markdown(f'<div class="result-box">{transcription_results["sphinx"]["text"]}</div>', 
                           unsafe_allow_html=True)
    
    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
    if analyze_emotion and 'emotion_analysis' in results:
        st.markdown("### ğŸ˜Š ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±")
        
        emotion_results = results['emotion_analysis']
        
        if 'emotions' in emotion_results:
            emotions_df = pd.DataFrame(emotion_results['emotions'])
            
            col1, col2 = st.columns([2, 1])
            
            with col1:
                # Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ Ù„Ù„Ù…Ø´Ø§Ø¹Ø±
                fig = px.bar(emotions_df, x='label', y='score', 
                           title="ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±",
                           color='score',
                           color_continuous_scale='viridis')
                fig.update_layout(xaxis_title="Ø§Ù„Ù…Ø´Ø§Ø¹Ø±", yaxis_title="Ø§Ù„Ø¯Ø±Ø¬Ø©")
                st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                st.markdown("**Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ù…ÙƒØªØ´ÙØ©:**")
                for emotion in emotion_results['emotions']:
                    st.metric(
                        emotion['label'],
                        f"{emotion['score']:.2%}",
                        delta=None
                    )
    
    # Ø®ØµØ§Ø¦Øµ Ø§Ù„ØµÙˆØª
    if extract_features and 'audio_features' in results:
        st.markdown("### ğŸµ Ø®ØµØ§Ø¦Øµ Ø§Ù„ØµÙˆØª")
        
        features = results['audio_features']
        
        if 'error' not in features:
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("Ø§Ù„Ù…Ø¯Ø© (Ø«Ø§Ù†ÙŠØ©)", f"{features['duration']:.2f}")
            
            with col2:
                st.metric("Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª", f"{features['sample_rate']:,}")
            
            with col3:
                st.metric("Ø·Ø§Ù‚Ø© Ø§Ù„ØµÙˆØª", f"{features['rms_energy']:.4f}")
            
            with col4:
                st.metric("Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø¹Ø¨ÙˆØ± Ø§Ù„ØµÙØ±ÙŠ", f"{features['zero_crossing_rate']:.4f}")
            
            # Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ Ù„Ù€ MFCC
            if 'mfcc' in features:
                st.markdown("**Ù…Ø¹Ø§Ù…Ù„Ø§Øª MFCC:**")
                mfcc_df = pd.DataFrame({
                    'Coefficient': range(1, len(features['mfcc']) + 1),
                    'Value': features['mfcc']
                })
                
                fig = px.line(mfcc_df, x='Coefficient', y='Value', 
                            title="Ù…Ø¹Ø§Ù…Ù„Ø§Øª MFCC")
                st.plotly_chart(fig, use_container_width=True)
    
    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªØ­Ø¯Ø«
    if speaker_analysis and 'speaker_characteristics' in results:
        st.markdown("### ğŸ‘¤ Ø®ØµØ§Ø¦Øµ Ø§Ù„Ù…ØªØ­Ø¯Ø«")
        
        speaker = results['speaker_characteristics']
        
        if 'error' not in speaker:
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("Ø§Ù„Ø¬Ù†Ø³ Ø§Ù„Ù…Ù‚Ø¯Ø±", speaker.get('estimated_gender', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'))
                st.metric("Ù†ÙˆØ¹ÙŠØ© Ø§Ù„ØµÙˆØª", speaker.get('voice_quality', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'))
            
            with col2:
                st.metric("Ù†Ø·Ø§Ù‚ Ø§Ù„Ù†Ø¨Ø±Ø©", f"{speaker.get('pitch_range', 0):.2f}")
                st.metric("Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø·Ø§Ù‚Ø©", f"{speaker.get('energy_level', 0):.4f}")
            
            with col3:
                st.metric("Ù…Ø¹Ø¯Ù„ Ø§Ù„ÙƒÙ„Ø§Ù…", f"{speaker.get('speaking_rate', 0):.2f}")
                st.metric("Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø§Ù„ØµÙˆØª", f"{speaker.get('voice_stability', 0):.2f}")

def display_advanced_analysis(results):
    """Ø¹Ø±Ø¶ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…"""
    
    st.markdown("## ğŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…")
    
    # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¹Ø§Ù…Ø©
    if 'audio_features' in results and 'error' not in results['audio_features']:
        features = results['audio_features']
        
        # Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ Ù„Ù„Ø·ÙŠÙ
        st.markdown("### ğŸŒŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø·ÙŠÙ")
        
        # Ù…Ø­Ø§ÙƒØ§Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø·ÙŠÙ (ÙÙŠ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØŒ Ø³ØªÙƒÙˆÙ† Ù…Ù† librosa)
        freq = np.linspace(0, 8000, 1000)
        magnitude = np.random.exponential(0.1, 1000) * np.exp(-freq/2000)
        
        fig = go.Figure()
        fig.add_trace(go.Scatter(x=freq, y=magnitude, mode='lines', name='Ø·ÙŠÙ Ø§Ù„ØµÙˆØª'))
        fig.update_layout(
            title="ØªØ­Ù„ÙŠÙ„ Ø·ÙŠÙ Ø§Ù„ØµÙˆØª",
            xaxis_title="Ø§Ù„ØªØ±Ø¯Ø¯ (Hz)",
            yaxis_title="Ø§Ù„Ù…Ù‚Ø¯Ø§Ø±",
            template="plotly_white"
        )
        st.plotly_chart(fig, use_container_width=True)
    
    # Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    if 'transcription' in results:
        st.markdown("### ğŸ”„ Ù…Ù‚Ø§Ø±Ù†Ø© Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­ÙˆÙŠÙ„")
        
        transcription = results['transcription']
        methods = []
        texts = []
        confidences = []
        
        for method, data in transcription.items():
            if isinstance(data, dict) and 'text' in data:
                methods.append(method.title())
                texts.append(data['text'])
                confidences.append(data.get('confidence', 0))
        
        if methods:
            comparison_df = pd.DataFrame({
                'Ø§Ù„Ø·Ø±ÙŠÙ‚Ø©': methods,
                'Ø§Ù„Ù†Øµ': texts,
                'Ø§Ù„Ø«Ù‚Ø©': confidences
            })
            
            st.dataframe(comparison_df, use_container_width=True)

def display_project_info():
    """Ø¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"""
    
    st.markdown("## â„¹ï¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø´Ø±ÙˆØ¹")
    
    st.markdown("""
    ### ğŸ¯ ÙˆØµÙ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
    Ù‡Ø°Ø§ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø¹Ø¨Ø§Ø±Ø© Ø¹Ù† Ù†Ø¸Ø§Ù… Ù…ØªÙ‚Ø¯Ù… Ù„ØªÙ…ÙŠÙŠØ² Ø§Ù„Ø£ØµÙˆØ§Øª ÙŠØ³ØªØ®Ø¯Ù… ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ 
    ÙˆØ§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØª ÙˆØªØ­ÙˆÙŠÙ„Ù‡ Ø¥Ù„Ù‰ Ù†Øµ Ù…Ø¹ Ø¥Ù…ÙƒØ§Ù†ÙŠØ§Øª ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± ÙˆØ®ØµØ§Ø¦Øµ Ø§Ù„Ù…ØªØ­Ø¯Ø«.
    
    ### ğŸš€ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
    - **ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ** Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…Ø§Ø°Ø¬ Ù…ØªØ¹Ø¯Ø¯Ø© (Whisper, Google Speech, Sphinx)
    - **ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±** Ù…Ù† Ù†Ø¨Ø±Ø© Ø§Ù„ØµÙˆØª
    - **Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø®ØµØ§Ø¦Øµ Ø§Ù„ØµÙˆØª** Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© (MFCC, Chroma, Tonnetz)
    - **ØªØ­Ù„ÙŠÙ„ Ø®ØµØ§Ø¦Øµ Ø§Ù„Ù…ØªØ­Ø¯Ø«** (Ø§Ù„Ø¬Ù†Ø³ØŒ Ù†ÙˆØ¹ÙŠØ© Ø§Ù„ØµÙˆØªØŒ Ù…Ø¹Ø¯Ù„ Ø§Ù„ÙƒÙ„Ø§Ù…)
    - **ÙˆØ§Ø¬Ù‡Ø© ØªÙØ§Ø¹Ù„ÙŠØ©** Ø³Ù‡Ù„Ø© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
    - **Ø¯Ø¹Ù… Ù„ØºØ§Øª Ù…ØªØ¹Ø¯Ø¯Ø©** (Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©ØŒ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©ØŒ Ø§Ù„ÙØ±Ù†Ø³ÙŠØ©ØŒ ÙˆØºÙŠØ±Ù‡Ø§)
    
    ### ğŸ› ï¸ Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©
    - **Python** - Ù„ØºØ© Ø§Ù„Ø¨Ø±Ù…Ø¬Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
    - **Streamlit** - ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠØ©
    - **PyTorch** - Ø¥Ø·Ø§Ø± Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ
    - **Transformers** - Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
    - **Librosa** - Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª
    - **Whisper** - ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ
    - **Plotly** - Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ© Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠØ©
    
    ### ğŸ“š Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
    Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ù…Ù„Ù `requirements.txt`
    
    ### ğŸ® ÙƒÙŠÙÙŠØ© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
    1. **ØªØ³Ø¬ÙŠÙ„ Ù…Ø¨Ø§Ø´Ø±**: Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ† Ù„ØªØ³Ø¬ÙŠÙ„ ØµÙˆØªÙƒ Ù…Ø¨Ø§Ø´Ø±Ø©
    2. **Ø±ÙØ¹ Ù…Ù„Ù**: Ø§Ø±ÙØ¹ Ù…Ù„Ù ØµÙˆØªÙŠ Ù…Ù† Ø¬Ù‡Ø§Ø²Ùƒ
    3. **Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù„ØºØ©**: Ø­Ø¯Ø¯ Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ù„ØªØ­Ù„ÙŠÙ„
    4. **ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„**: Ø§Ø­ØµÙ„ Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ Ù…ÙØµÙ„Ø© Ù„Ù„ØµÙˆØª
    
    ### âš ï¸ Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù…Ù‡Ù…Ø©
    - ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ† Ù…ØªØµÙ„ Ø¨Ø¬Ù‡Ø§Ø²Ùƒ Ù„Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±
    - Ù‚Ø¯ ÙŠØ³ØªØºØ±Ù‚ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¨Ø¶Ø¹ Ø¯Ù‚Ø§Ø¦Ù‚ ÙÙŠ Ø§Ù„Ù…Ø±Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰
    - Ø¬ÙˆØ¯Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ØªØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØª Ø§Ù„Ù…Ø¯Ø®Ù„
    - ÙŠØ¯Ø¹Ù… Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØª Ø¨ØµÙŠØº Ù…Ø®ØªÙ„ÙØ© (WAV, MP3, M4A, FLAC, OGG)
    """)
    
    # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©
    st.markdown("### ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø´Ø±ÙˆØ¹")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬", "3+")
    
    with col2:
        st.metric("Ø§Ù„Ù„ØºØ§Øª Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©", "6+")
    
    with col3:
        st.metric("ØµÙŠØº Ø§Ù„Ù…Ù„ÙØ§Øª", "5+")
    
    with col4:
        st.metric("Ù…ÙŠØ²Ø§Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„", "10+")

if __name__ == "__main__":
    main()