"""
Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª Ù†Ù…ÙˆØ°Ø¬ÙŠØ© Ù„Ù„ØªØ¯Ø±ÙŠØ¨
Create Sample Training Data
"""

import os
import numpy as np
import soundfile as sf
import librosa
from pathlib import Path
import json

def create_synthetic_voice(frequency, duration=3, sample_rate=22050, gender="male"):
    """
    Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØª Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
    
    Args:
        frequency: Ø§Ù„ØªØ±Ø¯Ø¯ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
        duration: Ø§Ù„Ù…Ø¯Ø© Ø¨Ø§Ù„Ø«ÙˆØ§Ù†ÙŠ
        sample_rate: Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø¹ÙŠÙ†Ø©
        gender: Ù†ÙˆØ¹ Ø§Ù„Ø¬Ù†Ø³ (Ù„ØªØ­Ø¯ÙŠØ¯ Ø®ØµØ§Ø¦Øµ Ø§Ù„ØµÙˆØª)
    
    Returns:
        Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
    """
    # Ø¥Ù†Ø´Ø§Ø¡ Ø¥Ø·Ø§Ø± Ø²Ù…Ù†ÙŠ
    t = np.linspace(0, duration, int(sample_rate * duration))
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…ÙˆØ¬Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
    audio = 0.3 * np.sin(2 * np.pi * frequency * t)
    
    # Ø¥Ø¶Ø§ÙØ© ØªÙˆØ§ÙÙ‚ÙŠØ§Øª Ù„Ù„ØµÙˆØª Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠ
    if gender == "male":
        # Ø£ØµÙˆØ§Øª Ø°ÙƒÙˆØ±ÙŠØ©: ØªØ±Ø¯Ø¯Ø§Øª Ù…Ù†Ø®ÙØ¶Ø© Ù…Ø¹ ØªÙˆØ§ÙÙ‚ÙŠØ§Øª Ù‚ÙˆÙŠØ©
        audio += 0.1 * np.sin(2 * np.pi * frequency * 2 * t)  # Ø§Ù„ØªÙˆØ§ÙÙ‚ÙŠ Ø§Ù„Ø«Ø§Ù†ÙŠ
        audio += 0.05 * np.sin(2 * np.pi * frequency * 3 * t)  # Ø§Ù„ØªÙˆØ§ÙÙ‚ÙŠ Ø§Ù„Ø«Ø§Ù„Ø«
    else:
        # Ø£ØµÙˆØ§Øª Ø£Ù†Ø«ÙˆÙŠØ©: ØªØ±Ø¯Ø¯Ø§Øª Ø¹Ø§Ù„ÙŠØ© Ù…Ø¹ ØªÙˆØ§ÙÙ‚ÙŠØ§Øª Ø£Ù‚Ù„
        audio += 0.08 * np.sin(2 * np.pi * frequency * 2 * t)
        audio += 0.03 * np.sin(2 * np.pi * frequency * 3 * t)
    
    # Ø¥Ø¶Ø§ÙØ© Ø¶ÙˆØ¶Ø§Ø¡ Ø·Ø¨ÙŠØ¹ÙŠØ©
    noise = 0.02 * np.random.randn(len(audio))
    audio += noise
    
    # ØªØ·Ø¨ÙŠÙ‚ envelope Ù„Ù„ØµÙˆØª Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠ
    envelope = np.exp(-t / duration * 2)  # Ø§Ù†Ø­Ø¯Ø§Ø± ØªØ¯Ø±ÙŠØ¬ÙŠ
    audio *= envelope
    
    return audio

def create_emotional_voice(base_frequency, emotion, duration=3, sample_rate=22050):
    """
    Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØª Ø¨Ø¹Ø§Ø·ÙØ© Ù…Ø¹ÙŠÙ†Ø©
    
    Args:
        base_frequency: Ø§Ù„ØªØ±Ø¯Ø¯ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
        emotion: Ø§Ù„Ø¹Ø§Ø·ÙØ©
        duration: Ø§Ù„Ù…Ø¯Ø©
        sample_rate: Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø¹ÙŠÙ†Ø©
    
    Returns:
        Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ Ø§Ù„Ø¹Ø§Ø·ÙÙŠ
    """
    t = np.linspace(0, duration, int(sample_rate * duration))
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…ÙˆØ¬Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
    audio = 0.3 * np.sin(2 * np.pi * base_frequency * t)
    
    # ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„ØµÙˆØª Ø­Ø³Ø¨ Ø§Ù„Ø¹Ø§Ø·ÙØ©
    if emotion == "happy":
        # ØµÙˆØª Ø³Ø¹ÙŠØ¯: ØªØ±Ø¯Ø¯Ø§Øª Ù…ØªØºÙŠØ±Ø© Ø¨Ø³Ø±Ø¹Ø©
        modulation = 1 + 0.3 * np.sin(2 * np.pi * 5 * t)
        audio *= modulation
        # Ø¥Ø¶Ø§ÙØ© ØªÙˆØ§ÙÙ‚ÙŠØ§Øª Ø¹Ø§Ù„ÙŠØ©
        audio += 0.1 * np.sin(2 * np.pi * base_frequency * 2 * t)
        
    elif emotion == "sad":
        # ØµÙˆØª Ø­Ø²ÙŠÙ†: ØªØ±Ø¯Ø¯Ø§Øª Ù…Ù†Ø®ÙØ¶Ø© ÙˆÙ…Ø³ØªÙ‚Ø±Ø©
        audio *= 0.7  # ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¹Ø©
        # Ø¥Ø¶Ø§ÙØ© ØªØ±Ø¯Ø¯Ø§Øª Ù…Ù†Ø®ÙØ¶Ø©
        audio += 0.1 * np.sin(2 * np.pi * base_frequency * 0.5 * t)
        
    elif emotion == "angry":
        # ØµÙˆØª ØºØ§Ø¶Ø¨: ØªØ±Ø¯Ø¯Ø§Øª Ø¹Ø§Ù„ÙŠØ© ÙˆÙ…ØªØºÙŠØ±Ø©
        modulation = 1 + 0.5 * np.sin(2 * np.pi * 8 * t)
        audio *= modulation
        # Ø¥Ø¶Ø§ÙØ© Ø¶ÙˆØ¶Ø§Ø¡
        noise = 0.05 * np.random.randn(len(audio))
        audio += noise
        
    elif emotion == "neutral":
        # ØµÙˆØª Ù…Ø­Ø§ÙŠØ¯: ØªØ±Ø¯Ø¯Ø§Øª Ù…Ø³ØªÙ‚Ø±Ø©
        audio += 0.05 * np.sin(2 * np.pi * base_frequency * 2 * t)
    
    # Ø¥Ø¶Ø§ÙØ© Ø¶ÙˆØ¶Ø§Ø¡ Ø·Ø¨ÙŠØ¹ÙŠØ©
    noise = 0.02 * np.random.randn(len(audio))
    audio += noise
    
    # ØªØ·Ø¨ÙŠÙ‚ envelope
    envelope = np.exp(-t / duration * 1.5)
    audio *= envelope
    
    return audio

def create_age_group_voice(base_frequency, age_group, duration=3, sample_rate=22050):
    """
    Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØª Ù„ÙØ¦Ø© Ø¹Ù…Ø±ÙŠØ© Ù…Ø¹ÙŠÙ†Ø©
    
    Args:
        base_frequency: Ø§Ù„ØªØ±Ø¯Ø¯ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
        age_group: Ø§Ù„ÙØ¦Ø© Ø§Ù„Ø¹Ù…Ø±ÙŠØ©
        duration: Ø§Ù„Ù…Ø¯Ø©
        sample_rate: Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø¹ÙŠÙ†Ø©
    
    Returns:
        Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ Ù„Ù„ÙØ¦Ø© Ø§Ù„Ø¹Ù…Ø±ÙŠØ©
    """
    t = np.linspace(0, duration, int(sample_rate * duration))
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…ÙˆØ¬Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
    audio = 0.3 * np.sin(2 * np.pi * base_frequency * t)
    
    # ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„ØµÙˆØª Ø­Ø³Ø¨ Ø§Ù„ÙØ¦Ø© Ø§Ù„Ø¹Ù…Ø±ÙŠØ©
    if age_group == "child":
        # ØµÙˆØª Ø·ÙÙ„: ØªØ±Ø¯Ø¯Ø§Øª Ø¹Ø§Ù„ÙŠØ© ÙˆÙ…ØªØºÙŠØ±Ø©
        modulation = 1 + 0.4 * np.sin(2 * np.pi * 6 * t)
        audio *= modulation
        # Ø¥Ø¶Ø§ÙØ© ØªÙˆØ§ÙÙ‚ÙŠØ§Øª Ø¹Ø§Ù„ÙŠØ©
        audio += 0.15 * np.sin(2 * np.pi * base_frequency * 2 * t)
        
    elif age_group == "young_adult":
        # ØµÙˆØª Ø´Ø§Ø¨: ØªØ±Ø¯Ø¯Ø§Øª Ù…ØªÙˆØ³Ø·Ø© Ù…Ø¹ ØªÙ†ÙˆØ¹
        modulation = 1 + 0.2 * np.sin(2 * np.pi * 3 * t)
        audio *= modulation
        audio += 0.1 * np.sin(2 * np.pi * base_frequency * 2 * t)
        
    elif age_group == "adult":
        # ØµÙˆØª Ø¨Ø§Ù„Øº: ØªØ±Ø¯Ø¯Ø§Øª Ù…Ø³ØªÙ‚Ø±Ø©
        audio += 0.08 * np.sin(2 * np.pi * base_frequency * 2 * t)
        
    elif age_group == "elderly":
        # ØµÙˆØª Ù…Ø³Ù†: ØªØ±Ø¯Ø¯Ø§Øª Ù…Ù†Ø®ÙØ¶Ø© Ù…Ø¹ Ø§Ù‡ØªØ²Ø§Ø²
        audio *= 0.8
        modulation = 1 + 0.1 * np.sin(2 * np.pi * 2 * t)
        audio *= modulation
        # Ø¥Ø¶Ø§ÙØ© ØªØ±Ø¯Ø¯Ø§Øª Ù…Ù†Ø®ÙØ¶Ø©
        audio += 0.1 * np.sin(2 * np.pi * base_frequency * 0.7 * t)
    
    # Ø¥Ø¶Ø§ÙØ© Ø¶ÙˆØ¶Ø§Ø¡ Ø·Ø¨ÙŠØ¹ÙŠØ©
    noise = 0.02 * np.random.randn(len(audio))
    audio += noise
    
    # ØªØ·Ø¨ÙŠÙ‚ envelope
    envelope = np.exp(-t / duration * 1.2)
    audio *= envelope
    
    return audio

def create_language_voice(base_frequency, language, duration=3, sample_rate=22050):
    """
    Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØª Ø¨Ù„ØºØ© Ù…Ø¹ÙŠÙ†Ø© (Ù…Ø­Ø§ÙƒØ§Ø©)
    
    Args:
        base_frequency: Ø§Ù„ØªØ±Ø¯Ø¯ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
        language: Ø§Ù„Ù„ØºØ©
        duration: Ø§Ù„Ù…Ø¯Ø©
        sample_rate: Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø¹ÙŠÙ†Ø©
    
    Returns:
        Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ Ù„Ù„ØºØ©
    """
    t = np.linspace(0, duration, int(sample_rate * duration))
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…ÙˆØ¬Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
    audio = 0.3 * np.sin(2 * np.pi * base_frequency * t)
    
    # ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„ØµÙˆØª Ø­Ø³Ø¨ Ø§Ù„Ù„ØºØ© (Ù…Ø­Ø§ÙƒØ§Ø©)
    if language == "arabic":
        # Ù…Ø­Ø§ÙƒØ§Ø© Ø®ØµØ§Ø¦Øµ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
        modulation = 1 + 0.25 * np.sin(2 * np.pi * 4 * t)
        audio *= modulation
        audio += 0.1 * np.sin(2 * np.pi * base_frequency * 1.5 * t)
        
    elif language == "english":
        # Ù…Ø­Ø§ÙƒØ§Ø© Ø®ØµØ§Ø¦Øµ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
        modulation = 1 + 0.15 * np.sin(2 * np.pi * 3 * t)
        audio *= modulation
        audio += 0.08 * np.sin(2 * np.pi * base_frequency * 2 * t)
        
    elif language == "french":
        # Ù…Ø­Ø§ÙƒØ§Ø© Ø®ØµØ§Ø¦Øµ Ø§Ù„Ù„ØºØ© Ø§Ù„ÙØ±Ù†Ø³ÙŠØ©
        modulation = 1 + 0.3 * np.sin(2 * np.pi * 5 * t)
        audio *= modulation
        audio += 0.12 * np.sin(2 * np.pi * base_frequency * 1.8 * t)
        
    elif language == "spanish":
        # Ù…Ø­Ø§ÙƒØ§Ø© Ø®ØµØ§Ø¦Øµ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ø³Ø¨Ø§Ù†ÙŠØ©
        modulation = 1 + 0.2 * np.sin(2 * np.pi * 3.5 * t)
        audio *= modulation
        audio += 0.09 * np.sin(2 * np.pi * base_frequency * 2.2 * t)
    
    # Ø¥Ø¶Ø§ÙØ© Ø¶ÙˆØ¶Ø§Ø¡ Ø·Ø¨ÙŠØ¹ÙŠØ©
    noise = 0.02 * np.random.randn(len(audio))
    audio += noise
    
    # ØªØ·Ø¨ÙŠÙ‚ envelope
    envelope = np.exp(-t / duration * 1.3)
    audio *= envelope
    
    return audio

def create_sample_dataset():
    """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù†Ù…ÙˆØ°Ø¬ÙŠØ© Ø´Ø§Ù…Ù„Ø©"""
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª
    data_dir = Path("data/raw")
    data_dir.mkdir(parents=True, exist_ok=True)
    
    sample_rate = 22050
    duration = 3
    
    # Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    training_data = []
    
    print("ğŸµ Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨...")
    
    # 1. ØªØµÙ†ÙŠÙ Ø§Ù„Ø¬Ù†Ø³
    print("ğŸ“Š Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª ØªØµÙ†ÙŠÙ Ø§Ù„Ø¬Ù†Ø³...")
    
    # Ø£ØµÙˆØ§Øª Ø°ÙƒÙˆØ±ÙŠØ©
    for i in range(10):
        frequency = 80 + i * 10  # ØªØ±Ø¯Ø¯Ø§Øª Ù…Ù†Ø®ÙØ¶Ø©
        audio = create_synthetic_voice(frequency, duration, sample_rate, "male")
        filename = f"male_voice_{i+1}.wav"
        filepath = data_dir / filename
        sf.write(filepath, audio, sample_rate)
        
        training_data.append({
            "file_path": str(filepath),
            "label": "male",
            "classification_type": "gender"
        })
    
    # Ø£ØµÙˆØ§Øª Ø£Ù†Ø«ÙˆÙŠØ©
    for i in range(10):
        frequency = 180 + i * 15  # ØªØ±Ø¯Ø¯Ø§Øª Ø¹Ø§Ù„ÙŠØ©
        audio = create_synthetic_voice(frequency, duration, sample_rate, "female")
        filename = f"female_voice_{i+1}.wav"
        filepath = data_dir / filename
        sf.write(filepath, audio, sample_rate)
        
        training_data.append({
            "file_path": str(filepath),
            "label": "female",
            "classification_type": "gender"
        })
    
    # 2. ØªØµÙ†ÙŠÙ Ø§Ù„Ø¹ÙˆØ§Ø·Ù
    print("ğŸ˜Š Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª ØªØµÙ†ÙŠÙ Ø§Ù„Ø¹ÙˆØ§Ø·Ù...")
    
    emotions = ["happy", "sad", "angry", "neutral"]
    for emotion in emotions:
        for i in range(5):
            frequency = 120 + i * 20
            audio = create_emotional_voice(frequency, emotion, duration, sample_rate)
            filename = f"{emotion}_voice_{i+1}.wav"
            filepath = data_dir / filename
            sf.write(filepath, audio, sample_rate)
            
            training_data.append({
                "file_path": str(filepath),
                "label": emotion,
                "classification_type": "emotion"
            })
    
    # 3. ØªØµÙ†ÙŠÙ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ø¹Ù…Ø±ÙŠØ©
    print("ğŸ‘¶ Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª ØªØµÙ†ÙŠÙ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ø¹Ù…Ø±ÙŠØ©...")
    
    age_groups = ["child", "young_adult", "adult", "elderly"]
    for age_group in age_groups:
        for i in range(4):
            frequency = 100 + i * 25
            audio = create_age_group_voice(frequency, age_group, duration, sample_rate)
            filename = f"{age_group}_voice_{i+1}.wav"
            filepath = data_dir / filename
            sf.write(filepath, audio, sample_rate)
            
            training_data.append({
                "file_path": str(filepath),
                "label": age_group,
                "classification_type": "age_group"
            })
    
    # 4. ØªØµÙ†ÙŠÙ Ø§Ù„Ù„ØºØ§Øª
    print("ğŸŒ Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª ØªØµÙ†ÙŠÙ Ø§Ù„Ù„ØºØ§Øª...")
    
    languages = ["arabic", "english", "french", "spanish"]
    for language in languages:
        for i in range(3):
            frequency = 130 + i * 20
            audio = create_language_voice(frequency, language, duration, sample_rate)
            filename = f"{language}_voice_{i+1}.wav"
            filepath = data_dir / filename
            sf.write(filepath, audio, sample_rate)
            
            training_data.append({
                "file_path": str(filepath),
                "label": language,
                "classification_type": "language"
            })
    
    # Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    print("ğŸ’¾ Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨...")
    
    # Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø©
    with open("data/training_data.json", "w", encoding="utf-8") as f:
        json.dump(training_data, f, ensure_ascii=False, indent=2)
    
    # Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„ØªØµÙ†ÙŠÙ
    for classification_type in ["gender", "emotion", "age_group", "language"]:
        filtered_data = [item for item in training_data 
                        if item["classification_type"] == classification_type]
        
        with open(f"data/{classification_type}_dataset.json", "w", encoding="utf-8") as f:
            json.dump(filtered_data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {len(training_data)} Ø¹ÙŠÙ†Ø© ØªØ¯Ø±ÙŠØ¨")
    print("ğŸ“ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©:")
    print("   - data/training_data.json (Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª)")
    print("   - data/gender_dataset.json (Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ù†Ø³)")
    print("   - data/emotion_dataset.json (Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹ÙˆØ§Ø·Ù)")
    print("   - data/age_group_dataset.json (Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ø¹Ù…Ø±ÙŠØ©)")
    print("   - data/language_dataset.json (Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù„ØºØ§Øª)")
    print("   - data/raw/ (Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØªÙŠØ©)")

def create_test_samples():
    """Ø¥Ù†Ø´Ø§Ø¡ Ø¹ÙŠÙ†Ø§Øª Ø§Ø®ØªØ¨Ø§Ø±"""
    
    data_dir = Path("data/test_samples")
    data_dir.mkdir(parents=True, exist_ok=True)
    
    sample_rate = 22050
    duration = 2
    
    print("ğŸ§ª Ø¥Ù†Ø´Ø§Ø¡ Ø¹ÙŠÙ†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±...")
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø¹ÙŠÙ†Ø§Øª Ø§Ø®ØªØ¨Ø§Ø± Ù…ØªÙ†ÙˆØ¹Ø©
    test_samples = [
        {"frequency": 90, "gender": "male", "emotion": "neutral"},
        {"frequency": 200, "gender": "female", "emotion": "happy"},
        {"frequency": 85, "gender": "male", "emotion": "angry"},
        {"frequency": 190, "gender": "female", "emotion": "sad"},
        {"frequency": 95, "gender": "male", "emotion": "happy"},
    ]
    
    for i, sample in enumerate(test_samples):
        audio = create_synthetic_voice(
            sample["frequency"], 
            duration, 
            sample_rate, 
            sample["gender"]
        )
        
        # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ø§Ø·ÙØ©
        audio = create_emotional_voice(
            sample["frequency"], 
            sample["emotion"], 
            duration, 
            sample_rate
        )
        
        filename = f"test_sample_{i+1}_{sample['gender']}_{sample['emotion']}.wav"
        filepath = data_dir / filename
        sf.write(filepath, audio, sample_rate)
        
        print(f"âœ… {filename}")
    
    print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {len(test_samples)} Ø¹ÙŠÙ†Ø© Ø§Ø®ØªØ¨Ø§Ø±")

if __name__ == "__main__":
    print("ğŸ¤ Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ÙŠØ©")
    print("=" * 50)
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    create_sample_dataset()
    create_test_samples()
    
    print("\nğŸ‰ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­!")
    print("ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø¢Ù† ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù…: python run.py --mode train")